

#### 前期准备

```
wget https://mirrors.tuna.tsinghua.edu.cn/apache/sqoop/1.4.7/sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz

--在hdfs创建sqoop_test
[11899517@bigdata4 ~]$ hadoop fs -ls /user/11899517/
Found 8 items
drwxr-x---   - 11899517 supergroup          0 2018-12-31 00:59 /user/11899517/flume_data
drwxr-x---   - 11899517 supergroup          0 2019-01-06 23:45 /user/11899517/hive
drwxr-x---   - 11899517 supergroup          0 2019-01-06 16:46 /user/11899517/hivetable
drwxr-x---   - 11899517 supergroup          0 2018-12-11 12:57 /user/11899517/input
drwxr-x---   - 11899517 supergroup          0 2019-01-08 13:29 /user/11899517/mrlogs
drwxr-x---   - 11899517 supergroup          0 2019-01-08 13:15 /user/11899517/output
drwxr-x---   - 11899517 supergroup          0 2018-12-16 18:03 /user/11899517/resource
drwxr-x---   - 11899517 supergroup          0 2019-01-06 20:31 /user/11899517/weblog
[11899517@bigdata4 ~]$ hadoop fs -mkdir /user/11899517/sqoop_test/
```

<li>个人习惯是下载到本地然后终端scp

```
qly@qlyComputer:~/下载$ sudo scp -i /home/qly/.ssh/11899517 sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz 11899517@10.173.32.6:/mnt/home/11899517/
[sudo] qly 的密码： 
sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz          100%   17MB   1.2MB/s   00:14    
qly@qlyComputer:~/下载$ sudo scp -i /home/qly/.ssh/11899517 mysql-connector-java-5.1.47.tar.gz 11899517@10.173.32.6:/mnt/home/11899517/
mysql-connector-java-5.1.47.tar.gz            100% 4348KB   1.4MB/s   00:03 
```

#### 配置环境变量

```
[11899517@bigdata4 ~]$ mv sqoop-1.4.7 sqoop
[11899517@bigdata4 ~]$ cd sqoop
[11899517@bigdata4 sqoop]$ ls
bin        CHANGELOG.txt  conf  ivy      lib          NOTICE.txt   README.txt       sqoop-patch-review.py  src
build.xml  COMPILING.txt  docs  ivy.xml  LICENSE.txt  pom-old.xml  sqoop-1.4.7.jar  sqoop-test-1.4.7.jar   testdata
[11899517@bigdata4 sqoop]$ cd conf
[11899517@bigdata4 conf]$ ls
oraoop-site-template.xml  sqoop-env-template.cmd  sqoop-env-template.sh  sqoop-site-template.xml  sqoop-site.xml
[11899517@bigdata4 conf]$ cp sqoop-env-template.sh sqoop-env.sh
[11899517@bigdata4 conf]$ vi sqoop-env.sh
[11899517@bigdata4 conf]$ which HADOOP_HOME
/usr/bin/which: no HADOOP_HOME in (/mnt/home/11899517/flume/bin:/home/hadoop/hadoop-current/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/puppetlabs/bin:/mnt/home/11899517/.local/bin:/mnt/home/11899517/bin)
```

#### 测试是否安装成功

```
--进入mysql命令界面，可查询数据
./sqoop import --connect "jdbc:mysql://10.173.32.6:3306/sqoop?characterEncoding=UTF-8&useCursorFetch=true" --username root --password Gg/ru,.#5 --table sqoop_test --delete-target-dir --target-dir /user/11899517/sqoop_test --split-by id
```

#### 安装mysql辅助驱动
<li>把辅助驱动jar包放到sqoop的lib目录下

```
[11899517@bigdata4 ~]$ ls -l
总用量 225328
-rw-r----- 1 11899517 11899517   1045083 1月   8 13:07 000000_0
-rw-rw-r-- 1 11899517 11899517   1980857 12月 16 17:57 17monipdb.dat
drwxrwxr-x 3 11899517 11899517      4096 1月  23 12:55 all_tar
drwxrwxr-x 8 11899517 11899517      4096 12月 29 22:55 flume
drwxrwxr-x 5 11899517 11899517      4096 1月   2 17:45 flumefile
drwxrwxr-x 3 11899517 11899517      4096 1月   2 17:47 flume_log
drwxrwxr-x 9 11899517 11899517      4096 1月   5 15:04 hive
drwxrwxr-x 3 11899517 11899517      4096 1月   5 14:59 hivefile
-rw-rw-r-- 1 11899517 11899517   2601605 12月 16 13:16 indata.txt
-rwxr-xr-x 1 11899517 11899517     80549 1月   5 16:09 json-serde-1.3.6-jar-with-dependencies.jar
-rw-r--r-- 1 11899517 11899517 158180009 1月   8 12:59 log0605-output
-rwxrwxr-x 1 11899517 11899517  54625074 12月 11 12:52 log0605.txt
-rw-r--r-- 1 11899517 11899517   1004838 1月  23 12:59 mysql-connector-java-5.1.46.jar
-rw-r--r-- 1 11899517 11899517   1007502 1月  23 12:55 mysql-connector-java-5.1.47.jar
-rw-r----- 1 11899517 11899517  10153717 1月   6 23:27 part00000
drwxrwxr-x 3 11899517 11899517      4096 12月 29 23:41 soft
drwxr-xr-x 9 11899517 11899517      4096 12月 19 2017 sqoop
[11899517@bigdata4 ~]$ cp mysql-connector-java-5.1.46.jar /mnt/home/11899517/sqoop/lib/
[11899517@bigdata4 ~]$ cd /mnt/home/11899517/sqoop/lib
[11899517@bigdata4 lib]$ ls
ant-contrib-1.0b3.jar          jackson-core-2.3.1.jar               parquet-column-1.6.0.jar
ant-eclipse-1.0-jvm1.2.jar     jackson-core-asl-1.9.13.jar          parquet-common-1.6.0.jar
avro-1.8.1.jar                 jackson-databind-2.3.1.jar           parquet-encoding-1.6.0.jar
avro-mapred-1.8.1-hadoop2.jar  jackson-mapper-asl-1.9.13.jar        parquet-format-2.2.0-rc1.jar
commons-codec-1.4.jar          kite-data-core-1.1.0.jar             parquet-generator-1.6.0.jar
commons-compress-1.8.1.jar     kite-data-hive-1.1.0.jar             parquet-hadoop-1.6.0.jar
commons-io-1.4.jar             kite-data-mapreduce-1.1.0.jar        parquet-jackson-1.6.0.jar
commons-jexl-2.1.1.jar         kite-hadoop-compatibility-1.1.0.jar  slf4j-api-1.6.1.jar
commons-lang3-3.4.jar          mysql-connector-java-5.1.46.jar      snappy-java-1.1.1.6.jar
commons-logging-1.1.1.jar      opencsv-2.3.jar                      xz-1.5.jar
hsqldb-1.8.0.10.jar            paranamer-2.7.jar
jackson-annotations-2.3.1.jar  parquet-avro-1.6.0.jar
```

#### 尝试从mysql到hdfs

```
[11899517@bigdata4 bin]$ ./sqoop import --connect "jdbc:mysql://10.173.32.6:3306/sqoop?characterEncoding=UTF-8&useCursorFetch=true" --username root --password Gg/ru,.#5 --table sqoop_test --delete-target-dir --target-dir /user/11899517/sqoop_test --split-by id
Warning: /mnt/home/11899517/sqoop/bin/../../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /mnt/home/11899517/sqoop/bin/../../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /mnt/home/11899517/sqoop/bin/../../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /mnt/home/11899517/sqoop/bin/../../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
19/01/23 13:17:46 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7
19/01/23 13:17:46 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
19/01/23 13:17:46 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
19/01/23 13:17:46 INFO tool.CodeGenTool: Beginning code generation
Wed Jan 23 13:17:47 CST 2019 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
19/01/23 13:17:47 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `sqoop_test` AS t LIMIT 1
19/01/23 13:17:47 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `sqoop_test` AS t LIMIT 1
19/01/23 13:17:47 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /home/hadoop/hadoop-current
注: /tmp/sqoop-11899517/compile/1ebc7a6842bf2618f9306b1d47c1dd78/sqoop_test.java使用或覆盖了已过时的 API。
注: 有关详细信息, 请使用 -Xlint:deprecation 重新编译。
19/01/23 13:17:48 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-11899517/compile/1ebc7a6842bf2618f9306b1d47c1dd78/sqoop_test.jar
19/01/23 13:17:49 INFO tool.ImportTool: Destination directory /user/11899517/sqoop_test deleted.
19/01/23 13:17:49 WARN manager.MySQLManager: It looks like you are importing from mysql.
19/01/23 13:17:49 WARN manager.MySQLManager: This transfer can be faster! Use the --direct
19/01/23 13:17:49 WARN manager.MySQLManager: option to exercise a MySQL-specific fast path.
19/01/23 13:17:49 INFO manager.MySQLManager: Setting zero DATETIME behavior to convertToNull (mysql)
19/01/23 13:17:49 INFO mapreduce.ImportJobBase: Beginning import of sqoop_test
19/01/23 13:17:49 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
19/01/23 13:17:49 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
19/01/23 13:17:50 INFO client.RMProxy: Connecting to ResourceManager at bigdata0/10.173.32.5:8032
Wed Jan 23 13:17:52 CST 2019 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
19/01/23 13:17:52 INFO db.DBInputFormat: Using read commited transaction isolation
19/01/23 13:17:52 INFO db.DataDrivenDBInputFormat: BoundingValsQuery: SELECT MIN(`id`), MAX(`id`) FROM `sqoop_test`
19/01/23 13:17:52 INFO db.IntegerSplitter: Split size: 0; Num splits: 4 from: 1 to: 2
19/01/23 13:17:52 INFO mapreduce.JobSubmitter: number of splits:2
19/01/23 13:17:52 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1547603700477_0827
19/01/23 13:17:52 INFO impl.YarnClientImpl: Submitted application application_1547603700477_0827
19/01/23 13:17:52 INFO mapreduce.Job: The url to track the job: http://bigdata0.novalocal:8088/proxy/application_1547603700477_0827/
19/01/23 13:17:52 INFO mapreduce.Job: Running job: job_1547603700477_0827
19/01/23 13:17:59 INFO mapreduce.Job: Job job_1547603700477_0827 running in uber mode : false
19/01/23 13:17:59 INFO mapreduce.Job:  map 0% reduce 0%
19/01/23 13:18:06 INFO mapreduce.Job:  map 100% reduce 0%
19/01/23 13:18:06 INFO mapreduce.Job: Job job_1547603700477_0827 completed successfully
19/01/23 13:18:06 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=284240
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=197
		HDFS: Number of bytes written=14
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=4
	Job Counters 
		Launched map tasks=2
		Other local map tasks=2
		Total time spent by all maps in occupied slots (ms)=7818
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=7818
		Total vcore-milliseconds taken by all map tasks=7818
		Total megabyte-milliseconds taken by all map tasks=8005632
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Input split bytes=197
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=137
		CPU time spent (ms)=3800
		Physical memory (bytes) snapshot=347947008
		Virtual memory (bytes) snapshot=4321046528
		Total committed heap usage (bytes)=288882688
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=14
19/01/23 13:18:06 INFO mapreduce.ImportJobBase: Transferred 14 bytes in 16.2136 seconds (0.8635 bytes/sec)
19/01/23 13:18:06 INFO mapreduce.ImportJobBase: Retrieved 2 records.
[11899517@bigdata4 bin]$ 
```

<li>查看数据

```
[11899517@bigdata4 ~]$ hadoop fs -ls /user/11899517/sqoop_test/
Found 3 items
-rw-r-----   3 11899517 supergroup          0 2019-01-23 13:18 /user/11899517/sqoop_test/_SUCCESS
-rw-r-----   3 11899517 supergroup          8 2019-01-23 13:18 /user/11899517/sqoop_test/part-m-00000
-rw-r-----   3 11899517 supergroup          6 2019-01-23 13:18 /user/11899517/sqoop_test/part-m-00001
[11899517@bigdata4 ~]$ hadoop fs -text /user/11899517/sqoop_test/part-m-00000
19/01/23 13:20:49 INFO lzo.GPLNativeCodeLoader: Loaded native gpl library from the embedded binaries
19/01/23 13:20:49 INFO lzo.LzoCodec: Successfully loaded & initialized native-lzo library [hadoop-lzo rev 5e360bdefd8923280b1a0234b845448050bf0caa]
1,allen
[11899517@bigdata4 ~]$ 
```
