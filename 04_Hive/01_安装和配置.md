#### 下载

```  
wget https://mirrors.tuna.tsinghua.edu.cn/apache/hive/hive-1.2.2/apache-hive-1.2.2-bin.tar.gz
```  

#### 解压缩

```  
tar -xzvf apache-hive-1.2.2-bin.tar.gz
mv apache-hive-1.2.2-bin  hive
```  

#### vi hive-env.sh

```  
//由于hive依赖hadoop环境
HADOOP_HOME=/home/hadoop/hadoop-current
```  

#### vi hive-default.xml
使用默认配置，不用修改

```  
cp hive-default.xml.template hive-default.xml 
```  

#### vi hive-site.xml

```  
cp hive-default.xml.template hive-site.xml 
//配置文件
<property>
        <name>system:java.io.tmpdir</name>
        <value>/mnt/home/11899517/hivefile/tmpdir</value>
</property>
<property>
        <name>system:user.name</name>
        <value>11899517</value>
</property>
<property>
        <name>hive.aux.jars.path</name>
        <value>file:///mnt/home/11899517/hive/lib/json-serde-1.3.6-jar-with-dependencies.jar</value>
</property>
```  
<ul>hive-site.xml 的优先级高于 hive-default.xml
json-serde-1.3.6-jar-with-dependencies.jar 须放在hive的lib文件夹中

#### 启动命令

```  
[11899517@bigdata4 hive]$ ./bin/hive
Logging initialized using configuration in jar:file:/mnt/home/11899517/hive/lib/hive-common-1.2.2.jar!/hive-log4j.properties
hive> show databases
    > show databases;
FAILED: ParseException line 2:0 missing EOF at 'show' near 'databases'
hive> show databases;
OK
default
Time taken: 0.268 seconds, Fetched: 1 row(s)
hive> 
```  

#### 建数据库和表
<li>尤其注意 ` 和 ' 的使用, 数据库名/表名/分区名用`,中文/包路径/数据路径用'

``` 
hive> create database if not exists bigdata;
OK
Time taken: 0.124 seconds
hive> show databases;
OK
bigdata
default
Time taken: 0.011 seconds, Fetched: 2 row(s)
hive> 

hive> CREATE EXTERNAL TABLE IF NOT EXISTS `bigdata.weblog1` ( 
    > `active_name` string COMMENT '事件名称',
    > `order_id` string COMMENT '订单id' )
    > ROW FORMAT SERDE
    > 'org.openx.data.jsonserde.JsonSerDe'
    > STORED AS INPUTFORMAT
    > 'org.apache.hadoop.mapred.TextInputFormat'
    > OUTPUTFORMAT
    > 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
    > LOCATION
    > '/user/11899517/weblog/weblog';
OK
Time taken: 0.294 seconds
hive> 
``` 

## 依据教学内容--开始
#### 建表&&分区
``` 
--日志表建表语句
hive> CREATE EXTERNAL TABLE IF NOT EXISTS `bigdata.weblog`(
    > `time_tag` bigint COMMENT '时间',
    > `active_name` string COMMENT '事件名称',
    > `device_id` string COMMENT '设备id',
    > `session_id` string COMMENT '会话id',
    > `user_id` string COMMENT '用户id',
    > `ip` string COMMENT 'ip地址',
    > `adress` map<string,string> COMMENT '地址',
    > `req_url` string COMMENT 'http请求地址',
    > `action_path` string COMMENT '访问路径',
    > `product_id` string COMMENT '商品id',
    > `order_id` string COMMENT '订单id')
    > PARTITIONED BY(
    > `day` string COMMENT '日期')
    > ROW FORMAT SERDE
    > 'org.openx.data.jsonserde.JsonSerDe'
    > STORED AS INPUTFORMAT
    > 'org.apache.hadoop.mapred.TextInputFormat'
    > OUTPUTFORMAT
    > 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'
    > LOCATION
    > '/user/11899517/weblog/weblog';
OK
Time taken: 0.056 seconds

--查看表结构和信息
hive> desc bigdata.weblog;
OK
time_tag            	bigint              	时间                  
active_name         	string              	事件名称                
device_id           	string              	设备id                
session_id          	string              	会话id                
user_id             	string              	用户id                
ip                  	string              	ip地址                
adress              	map<string,string>  	地址                  
req_url             	string              	http请求地址            
action_path         	string              	访问路径                
product_id          	string              	商品id                
order_id            	string              	订单id                
day                 	string              	日期                  
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
	 	 
day                 	string              	日期                  
Time taken: 0.67 seconds, Fetched: 17 row(s)

--手动建立分区
hive> ALTER TABLE bigdata.weblog ADD PARTITION (day='2018-05-30') location '/user/11899517/weblog/weblog/day=2018-05-30';
OK
Time taken: 0.158 seconds

--查看表分区
hive> show partitions bigdata.weblog;
OK
day=2018-05-29
day=2018-05-30
Time taken: 0.055 seconds, Fetched: 2 row(s)
``` 

#### 

``` 

``` 
#### 

``` 

``` 
#### 

``` 

``` 
#### 

``` 

``` 



#### 

``` 

``` 



#### 

``` 

``` 
