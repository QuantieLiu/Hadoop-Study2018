
<li>亮点
  
```
解决大表与大表间的 Join 问题，分桶其实就是把大表化成了“小表”，然后 Map-Side Join 解决之，这是典型的分而治之的思想
```

#### 分区partition

实际是一个文件夹
<li>实现细节
  
```
1、一个表可以拥有一个或者多个分区，每个分区以文件夹的形式单独存在表文件夹的目录下
2、表和列名不区分大小写
3、分区是以字段的形式在表结构中存在，通过describe table命令可以查看到字段存在，但是该字段不存放实际的数据内容，仅仅是分区的表示（伪列）
```

<li>语法
  
```
1. 创建一个分区表，以 ds 为分区列： 
create table invites (id int, name string) partitioned by (ds string) row format delimited fields terminated by 't' stored as textfile; 
2. 将数据添加到时间为 2013-08-16 这个分区中： 
load data local inpath '/home/hadoop/Desktop/data.txt' overwrite into table invites partition (ds='2013-08-16'); 
3. 将数据添加到时间为 2013-08-20 这个分区中： 
load data local inpath '/home/hadoop/Desktop/data.txt' overwrite into table invites partition (ds='2013-08-20'); 
4. 从一个分区中查询数据： 
select * from invites where ds ='2013-08-12'; 
5.  往一个分区表的某一个分区中添加数据： 
insert overwrite table invites partition (ds='2013-08-12') select id,max(name) from test group by id; 
可以查看分区的具体情况，使用命令： 
hadoop fs -ls /home/hadoop.hive/warehouse/invites 
或者： 
show partitions tablename;
```

#### 桶bucket
  
```
更为细粒度的数据范围划分
采用对列值哈希，然后除以桶的个数求余的方式决定该条记录存放在哪个桶当中
```

<li>主要目的
  
```
1 获得更高的查询处理效率。桶为表加上了额外的结构，Hive 在处理有些查询时能利用这个结构。具体而言，连接两个在（包含连接列的）相同列上划分了桶的表，
  可以使用 Map 端连接 （Map-side join）高效的实现。比如JOIN操作。对于JOIN操作两个表有一个相同的列，如果对这两个表都进行了桶操作。
  那么将保存相同列值的桶进行JOIN操作就可以，可以大大较少JOIN的数据量
2 使取样（sampling）更高效。在处理大规模数据集时，在开发和修改查询的阶段，在数据集的一小部分数据上试运行查询
```

<li>创建带桶的 table 

```
--使用CLUSTERED BY 子句来指定划分桶所用的列和要划分的桶的个数
create table bucketed_user(id int,name string) clustered by (id) sorted by(name) into 4 buckets row format delimited fields terminated by '\t' stored as textfile; 

--使用用户ID来确定如何划分桶(Hive使用对值进行哈希并将结果除 以桶的个数取余数
--任何一桶里都会有一个随机的用户集合
CREATE TABLE bucketed_user (id INT) name STRING) 
CLUSTERED BY (id) INTO 4 BUCKETS; 
```

```
对于map端连接的情况，两个表以相同方式划分桶。处理左边表内某个桶的 mapper知道右边表内相匹配的行在对应的桶内。
因此，mapper只需要获取那个桶 (这只是右边表内存储数据的一小部分)即可进行连接。
这一优化方法并不一定要求 两个表必须桶的个数相同，两个表的桶个数是倍数关系也可以

桶中的数据可以根据一个或多个列另外进行排序。由于这样对每个桶的连接变成了高效的归并排序(merge-sort), 因此可以进一步提升map端连接的效率

CREATE TABLE bucketed_users (id INT, name STRING) 
CLUSTERED BY (id) SORTED BY (id ASC) INTO 4 BUCKETS; 
```

<li>填充数据
  
```
要向分桶表中填充成员，需要将 hive.enforce.bucketing 属性设置为 true。
这样，Hive 就知道用表定义中声明的数量来创建桶。然后使用 INSERT 命令即可。
需要注意的是： clustered by和sorted by不会影响数据的导入，这意味着，用户必须自己负责数据如何如何导入，包括数据的分桶和排序。 

'set hive.enforce.bucketing = true' 可以自动控制上一轮reduce的数量从而适配bucket的个数，
当然，用户也可以自主设置mapred.reduce.tasks去适配bucket个数，推荐使用'set hive.enforce.bucketing = true' 
```

```
INSERT OVERWRITE TABLE bucketed_users SELECT * FROM users; 

物理上，每个桶就是表(或分区）目录里的一个文件。它的文件名并不重要，但是桶 n 是按照字典序排列的第 n 个文件。
事实上，桶对应于 MapReduce 的输出文件分区：一个作业产生的桶(输出文件)和reduce任务个数相同。
```

<li>采样
  
```

```
<li>
  
```

```
