
<li>核心模块:
元数据节点(Namenode) && 数据节点(datanode)

--待插入图片02004

```
1 Client发起文件上传请求 --->  通过RPC与NameNode建立通讯
2 NameNode收到Client请求后，获取DataNode信息，并将可存储文件的节点信息返回给Client
3 Client收到NameNode返回的信息，与对应的DataNode节点取得联系，并向该节点写文件
4 文件写入到DataNode后，以流水线的方式复制到其他DataNode(涉及DataNode向NameNode申请block)
相关配置：hdfs-default.xml -- dfs.replication
```

<li>NameNode Metadata--<代码扩展>

```
fsimage:元数据镜像文件。存储某一时段NameNode内存元数据信息。
edits:操作日志文件。
fstime:保存最近一次checkpoint的时间
相关配置：hdfs-default.xml -- dfs.namenode.checkpoint.period   默认为3600秒
```

待插入图片02001

```
metedata主要存储了文件名称(FileName)，副本数量(replicas)，分多少block存储（block-ids），分别存储在哪个节点上（id2host）等
```

```
1 namenode接收“写请求”时，先向edit文件中写日志，成功后修改内存，并向客户端返回
2 hadoop会维护一个fsimage文件（namenode中metedata的镜像）
3 fsimage每隔一段时间通过合并edits文件来更新内容，并非实时一致
4 Secondary(Secondary namenode)，合并fsimage和edits文件并更新NameNode的metedata
```

<li>Secondary namenode工作流程

```
secondary通知namenode切换edits文件
secondary通过http请求从namenode获得fsimage和edits文件
secondary将fsimage载入内存，然后开始合并edits
secondary将新的fsimage发回给namenode
namenode用新的fsimage替换旧的fsimage
```

待插入图片02002

<li>文件下载

待插入图片02003

主要流程：

```
1 client向namenode发送请求
2 namenode查看Metadata信息，返回test.log的blok的位置
3 开始从节点h0下载block1,block2
```



