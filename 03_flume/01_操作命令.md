#### 安装

<li>下载、压缩命令跳过
<li>在~/.bashrc配置环境变量
  
```  
export FLUME_HOME=/mnt/home/11899517/flumeexport PATH=$FLUME_HOME/bin:$PATH
```  

<li>flume-env.sh(可选)
<li>一般情况都不需要修改，直接使用flume提供的模板文件即可，这里因为JAVA_HOME环境变量有点问题，稍作配置

```  
export JAVA_HOME=/mnt/home/11899517/soft/jdk1.8.0_11

# Give Flume more memory and pre-allocate, enable remote monitoring via JMX
# export JAVA_OPTS="-Xms100m -Xmx2000m -Dcom.sun.management.jmxremote"

# Let Flume write raw event data and configuration information to its log files for debugging
# purposes. Enabling these flags is not recommended in production,
# as it may result in logging sensitive user information or encryption secrets.
# export JAVA_OPTS="$JAVA_OPTS -Dorg.apache.flume.log.rawdata=true -Dorg.apache.flume.log.printconfig=true "

# Note that the Flume conf directory is always included in the classpath.
#FLUME_CLASSPATH=""

```  

#### 配置1-输出到控制台

<li>flume-conf-netsrc.properties
  
```  
agent.sources = netSrc
agent.channels = memoryChannel
agent.sinks = loggerSink

# For each one of the sources, the type is defined
agent.sources.netSrc.type = netcat
agent.sources.netSrc.bind = 0.0.0.0
agent.sources.netSrc.port = 12345

# The channel can be defined as follows.
agent.sources.netSrc.channels = memoryChannel

# Each sink's type must be defined
agent.sinks.loggerSink.type = logger

#Specify the channel the sink should use
agent.sinks.loggerSink.channel = memoryChannel

# Each channel's type is defined.
agent.channels.memoryChannel.type = memory

# Other config values specific to each type of channel(sink or source)
# can be defined as well
# In this case, it specifies the capacity of the memory channel
agent.channels.memoryChannel.capacity = 100

```  
  
#### 启动命令

```  
./bin/flume-ng agent --conf conf --conf-file conf/flume-conf-netsrc.properties --name agent -Dflume.root.logger=INFO,console
//flume-conf-netsrc.properties是配置文件的名称
```  

<li>启动成功的控制台输出

```  
2018-12-30 22:14:51,382 (conf-file-poller-0) [INFO - org.apache.flume.node.Application.startAllComponents(Application.java:182)] Starting Source netSrc
2018-12-30 22:14:51,382 (lifecycleSupervisor-1-0) [INFO - org.apache.flume.source.NetcatSource.start(NetcatSource.java:155)] Source starting
2018-12-30 22:14:51,400 (lifecycleSupervisor-1-0) [INFO - org.apache.flume.source.NetcatSource.start(NetcatSource.java:166)] Created serverSocket:sun.nio.ch.ServerSocketChannelImpl[/0:0:0:0:0:0:0:0:12345]
```  

<li>telnet本机端口
  
```  
[11899517@bigdata4 ~]$ telnet localhost 12345
Trying ::1...
Connected to localhost.
Escape character is '^]'.
hello qly
OK
```  

<li>相应的输出

```  
2018-12-30 22:15:47,100 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: { headers:{} body: 68 65 6C 6C 6F 20 71 6C 79 0D                   hello qly. }
```  

#### 配置2-输出到本地文件

<li>flume-conf-netsrc2localhost.properties

```  
agent.sources = netSrc
agent.channels = memoryChannel
agent.sinks = fileSink

# For each one of the sources, the type is defined
agent.sources.netSrc.type = netcat
agent.sources.netSrc.bind = 0.0.0.0
agent.sources.netSrc.port = 12345

# The channel can be defined as follows.
agent.sources.netSrc.channels = memoryChannel

# Each sink's type must be defined
agent.sinks.fileSink.type = file_roll
# 需提前创建的文件路径
agent.sinks.fileSink.sink.directory = /mnt/home/11899517/flumefile/file_roll/data
agent.sinks.fileSink.sink.rollInterval = 60

#Specify the channel the sink should use
agent.sinks.fileSink.channel = memoryChannel

# Each channel's type is defined.
agent.channels.memoryChannel.type = memory

# Other config values specific to each type of channel(sink or source)
# can be defined as well
# In this case, it specifies the capacity of the memory channel
agent.channels.memoryChannel.capacity = 100
```  

<li>agent.sinks.fileSink.sink.directory的文件夹需提前创建
	
```  
mkdir -p flumefile/file_roll/data
``` 

<li>telnet后，查看文件
	
```  
[11899517@bigdata4 data]$ cat 1546186066129-1
sfasfjlaskdfasdfklasdf
[11899517@bigdata4 data]$ cat 1546186066129-1
sfasfjlaskdfasdfklasdf
[11899517@bigdata4 data]$ ls
1546186066129-1  1546186066129-2
[11899517@bigdata4 data]$ cat 1546186066129-2
qqqlysfdsfas
herry lau
```  	

#### 配置3-输出到hdfs
<li> flume-conf-taildir2hdfs.properties

```  
agent.sources = fileSrc 
agent.channels = memoryChannel
agent.sinks = hdfsSink

# For each one of the sources, the type is defined
agent.sources.fileSrc.type = taildir
agent.sources.fileSrc.positionFile = /mnt/home/11899517/flumefile/hdfs_sink/mem_ch/positionFile
agent.sources.fileSrc.filegroups = f1
agent.sources.fileSrc.filegroups.f1 = /mnt/hadoop/log/.*.log

# The channel can be defined as follows.
agent.sources.fileSrc.channels = memoryChannel

# Each sink's type must be defined
agent.sinks.hdfsSink.type = logger
agent.sinks.hdfsSink.hdfs.path = /user/11899517/flume_data/mem_ch/%Y-%m-%d
agent.sinks.hdfsSink.hdfs.useLocalTimeStamp = true
agnet.sinks.hdfsSink.hdfs.fileType = DataStream
agent.sinks.hdfsSink.hdfs.rollSize = 0
agent.sinks.hdfsSink.hdfs.rollCount = 0
agent.sinks.hdfsSink.hdfs.rollInterval = 60

#Specify the channel the sink should use
agent.sinks.hdfsSink.channel = memoryChannel

# Each channel's type is defined.
agent.channels.memoryChannel.type = memory

# Other config values specific to each type of channel(sink or source)
# can be defined as well
# In this case, it specifies the capacity of the memory channel
agent.channels.memoryChannel.capacity = 100
```  

<li>agent.sinks.hdfsSink.hdfs.path需提前创建

``` 
[11899517@bigdata4 ~]$ hadoop fs -mkdir /user/11899517/flume_data/
[11899517@bigdata4 ~]$ hadoop fs -mkdir /user/11899517/flume_data/mem_ch/
``` 


<li>启动命令

``` 
[11899517@bigdata4 flume]$ ./bin/flume-ng agent --conf conf --conf-file conf/flume-conf-taildir2hdfs.properties --name agent
Info: Sourcing environment configuration script /mnt/home/11899517/flume/conf/flume-env.sh
Info: Including Hadoop libraries found via (/home/hadoop/hadoop-current/bin/hadoop) for HDFS access
Info: Including Hive libraries found via () for Hive access
+ exec /mnt/home/11899517/soft/jdk1.8.0_11/bin/java -Xmx20m -cp '/mnt/home/11899517/flume/conf:/mnt/home/11899517/flume/lib/*:/home/hadoop/hadoop-current/bin:/mnt/home/11899517/flume/bin:/home/hadoop/hadoop-current/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/puppetlabs/bin:/mnt/home/11899517/.local/bin:/mnt/home/11899517/bin:/home/hadoop/hadoop-2.7.6/etc/hadoop:/home/hadoop/hadoop-2.7.6/share/hadoop/common/lib/*:/home/hadoop/hadoop-2.7.6/share/hadoop/common/*:/home/hadoop/hadoop-2.7.6/share/hadoop/hdfs:/home/hadoop/hadoop-2.7.6/share/hadoop/hdfs/lib/*:/home/hadoop/hadoop-2.7.6/share/hadoop/hdfs/*:/home/hadoop/hadoop-2.7.6/share/hadoop/yarn/lib/*:/home/hadoop/hadoop-2.7.6/share/hadoop/yarn/*:/home/hadoop/hadoop-2.7.6/share/hadoop/mapreduce/lib/*:/home/hadoop/hadoop-2.7.6/share/hadoop/mapreduce/*:/home/hadoop/hadoop-current/contrib/capacity-scheduler/*.jar:/lib/*' -Djava.library.path=:/home/hadoop/hadoop-2.7.6/lib/native org.apache.flume.node.Application --conf-file conf/flume-conf-taildir2hdfs.properties --name agent
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/mnt/home/11899517/flume/lib/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/hadoop/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
``` 





### 报错信息
<li>flume未正常启动或防火墙设置

```  
[11899517@bigdata4 ~]$ telnet localhost 33602
Trying ::1...
telnet: connect to address ::1: Connection refused
Trying 127.0.0.1...
telnet: connect to address 127.0.0.1: Connection refused
```  

<li>启动命令有误导致启动失败
  
```  
//agent和-Dflume之间有空格
[11899517@bigdata4 flume]$ ./bin/flume-ng agent --conf conf --conf-file conf/flume-conf-netsrc.properties --name agent -Dflume.root.logger = INFO,console
Info: Sourcing environment configuration script /mnt/home/11899517/flume/conf/flume-env.sh
Info: Including Hadoop libraries found via (/home/hadoop/hadoop-current/bin/hadoop) for HDFS access
Info: Including Hive libraries found via () for Hive access
+ exec /mnt/home/11899517/soft/jdk1.8.0_11/bin/java -Xmx20m -cp '/mnt/home/11899517/flume/conf:/mnt/home/11899517/flume/lib/*:/home/hadoop/hadoop-2.7.6/etc/hadoop:/home/hadoop/hadoop-2.7.6/share/hadoop/common/lib/*:/home/hadoop/hadoop-2.7.6/share/hadoop/common/*:/home/hadoop/hadoop-2.7.6/share/hadoop/hdfs:/home/hadoop/hadoop-2.7.6/share/hadoop/hdfs/lib/*:/home/hadoop/hadoop-2.7.6/share/hadoop/hdfs/*:/home/hadoop/hadoop-2.7.6/share/hadoop/yarn/lib/*:/home/hadoop/hadoop-2.7.6/share/hadoop/yarn/*:/home/hadoop/hadoop-2.7.6/share/hadoop/mapreduce/lib/*:/home/hadoop/hadoop-2.7.6/share/hadoop/mapreduce/*:/home/hadoop/hadoop-current/contrib/capacity-scheduler/*.jar:/lib/*' -Djava.library.path=:/home/hadoop/hadoop-2.7.6/lib/native org.apache.flume.node.Application --conf-file conf/flume-conf-netsrc.properties --name agent-Dflume.root.logger = INFO,console
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/mnt/home/11899517/flume/lib/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/hadoop/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
```  

<li>fileSink配置有误,导致启动正常但是无法往目录文件路径写入数据
<li>Sink fileSink has been removed due to an error during configuration

```  
[11899517@bigdata4 flume]$ ./bin/flume-ng agent --conf conf --conf-file conf/flume-conf-netsrc2localhost.properties --name agent -Dflume.root.logger=INFO,console
2018-12-30 23:39:16,540 (conf-file-poller-0) [ERROR - org.apache.flume.node.AbstractConfigurationProvider.loadSinks(AbstractConfigurationProvider.java:426)] Sink fileSink has been removed due to an error during configuration
java.lang.IllegalArgumentException: Directory may not be null
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:88)
	at org.apache.flume.sink.RollingFileSink.configure(RollingFileSink.java:90)
```  

<li>sink配置有误，核对

```  
2018-12-31 00:02:57,264 (conf-file-poller-0) [ERROR - org.apache.flume.node.AbstractConfigurationProvider.loadSinks(AbstractConfigurationProvider.java:426)] Sink fileSink has been removed due to an error during configuration
```  
